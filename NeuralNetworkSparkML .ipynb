{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OGPGrQWcWppe"
      },
      "source": [
        "<h>Spark ML <h>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "K6zvamDPWsol",
        "outputId": "2018fa8c-7894-4995-9900-ab44db6ce2b3"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: pyspark in c:\\users\\khaye\\pycharmprojects\\pythonproject1\\.venv\\lib\\site-packages (3.2.4)\n",
            "Requirement already satisfied: py4j==0.10.9.5 in c:\\users\\khaye\\pycharmprojects\\pythonproject1\\.venv\\lib\\site-packages (from pyspark) (0.10.9.5)\n"
          ]
        }
      ],
      "source": [
        "! pip install pyspark"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "_dtoNK95Wppm"
      },
      "outputs": [],
      "source": [
        "from pyspark.sql import SparkSession\n",
        "from pyspark.ml import Pipeline\n",
        "from pyspark.ml.feature import StringIndexer # Perform encoding\n",
        "from pyspark.ml.feature import VectorAssembler\n",
        "from pyspark.ml.classification import MultilayerPerceptronClassifier\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "_iu4H5TZWppq"
      },
      "outputs": [
        {
          "ename": "RuntimeError",
          "evalue": "Java gateway process exited before sending its port number",
          "output_type": "error",
          "traceback": [
            "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[1;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
            "\u001b[1;32m<ipython-input-7-5882325587fa>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mspark\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mSparkSession\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbuilder\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappName\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"PySparkTitanikJob\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mgetOrCreate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
            "\u001b[1;32mc:\\Users\\khaye\\PycharmProjects\\pythonProject1\\.venv\\lib\\site-packages\\pyspark\\sql\\session.py\u001b[0m in \u001b[0;36mgetOrCreate\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    226\u001b[0m                             \u001b[0msparkConf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mset\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    227\u001b[0m                         \u001b[1;31m# This SparkContext may be an existing one.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 228\u001b[1;33m                         \u001b[0msc\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mSparkContext\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mgetOrCreate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msparkConf\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    229\u001b[0m                     \u001b[1;31m# Do not update `SparkConf` for existing `SparkContext`, as it's shared\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    230\u001b[0m                     \u001b[1;31m# by all sessions.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
            "\u001b[1;32mc:\\Users\\khaye\\PycharmProjects\\pythonProject1\\.venv\\lib\\site-packages\\pyspark\\context.py\u001b[0m in \u001b[0;36mgetOrCreate\u001b[1;34m(cls, conf)\u001b[0m\n\u001b[0;32m    390\u001b[0m         \u001b[1;32mwith\u001b[0m \u001b[0mSparkContext\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_lock\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    391\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mSparkContext\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_active_spark_context\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 392\u001b[1;33m                 \u001b[0mSparkContext\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mconf\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mconf\u001b[0m \u001b[1;32mor\u001b[0m \u001b[0mSparkConf\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    393\u001b[0m             \u001b[1;32mreturn\u001b[0m \u001b[0mSparkContext\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_active_spark_context\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    394\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
            "\u001b[1;32mc:\\Users\\khaye\\PycharmProjects\\pythonProject1\\.venv\\lib\\site-packages\\pyspark\\context.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, master, appName, sparkHome, pyFiles, environment, batchSize, serializer, conf, gateway, jsc, profiler_cls)\u001b[0m\n\u001b[0;32m    142\u001b[0m                 \" is not allowed as it is a security risk.\")\n\u001b[0;32m    143\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 144\u001b[1;33m         \u001b[0mSparkContext\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_ensure_initialized\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mgateway\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mgateway\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mconf\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mconf\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    145\u001b[0m         \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    146\u001b[0m             self._do_init(master, appName, sparkHome, pyFiles, environment, batchSize, serializer,\n",
            "\u001b[1;32mc:\\Users\\khaye\\PycharmProjects\\pythonProject1\\.venv\\lib\\site-packages\\pyspark\\context.py\u001b[0m in \u001b[0;36m_ensure_initialized\u001b[1;34m(cls, instance, gateway, conf)\u001b[0m\n\u001b[0;32m    337\u001b[0m         \u001b[1;32mwith\u001b[0m \u001b[0mSparkContext\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_lock\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    338\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mSparkContext\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_gateway\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 339\u001b[1;33m                 \u001b[0mSparkContext\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_gateway\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mgateway\u001b[0m \u001b[1;32mor\u001b[0m \u001b[0mlaunch_gateway\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mconf\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    340\u001b[0m                 \u001b[0mSparkContext\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_jvm\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mSparkContext\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_gateway\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mjvm\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    341\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
            "\u001b[1;32mc:\\Users\\khaye\\PycharmProjects\\pythonProject1\\.venv\\lib\\site-packages\\pyspark\\java_gateway.py\u001b[0m in \u001b[0;36mlaunch_gateway\u001b[1;34m(conf, popen_kwargs)\u001b[0m\n\u001b[0;32m    106\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    107\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mos\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0misfile\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mconn_info_file\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 108\u001b[1;33m                 \u001b[1;32mraise\u001b[0m \u001b[0mRuntimeError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"Java gateway process exited before sending its port number\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    109\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    110\u001b[0m             \u001b[1;32mwith\u001b[0m \u001b[0mopen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mconn_info_file\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"rb\"\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0minfo\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
            "\u001b[1;31mRuntimeError\u001b[0m: Java gateway process exited before sending its port number"
          ]
        }
      ],
      "source": [
        "#Create a Spark session\n",
        "spark = SparkSession.builder \\\n",
        "    .appName(\"NeuralNetworkExample\") \\\n",
        "    .getOrCreate()\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 219
        },
        "id": "BlfwVjSsWpps",
        "outputId": "33059f52-2edc-40ff-a0b4-ff91c6859fcd"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "\n",
              "            <div>\n",
              "                <p><b>SparkSession - in-memory</b></p>\n",
              "                \n",
              "        <div>\n",
              "            <p><b>SparkContext</b></p>\n",
              "\n",
              "            <p><a href=\"http://a69832b3bacd:4040\">Spark UI</a></p>\n",
              "\n",
              "            <dl>\n",
              "              <dt>Version</dt>\n",
              "                <dd><code>v3.5.1</code></dd>\n",
              "              <dt>Master</dt>\n",
              "                <dd><code>local[*]</code></dd>\n",
              "              <dt>AppName</dt>\n",
              "                <dd><code>PySparkTitanikJob</code></dd>\n",
              "            </dl>\n",
              "        </div>\n",
              "        \n",
              "            </div>\n",
              "        "
            ],
            "text/plain": [
              "<pyspark.sql.session.SparkSession at 0x78d105c06530>"
            ]
          },
          "execution_count": 10,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "spark"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KFVvaBVzWppt",
        "outputId": "0841d05f-5b7e-455c-c5bd-a3861599557f"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "root\n",
            " |-- Survived: integer (nullable = true)\n",
            " |-- Pclass: integer (nullable = true)\n",
            " |-- Sex: string (nullable = true)\n",
            " |-- Age: double (nullable = true)\n",
            " |-- SibSp: integer (nullable = true)\n",
            " |-- Parch: integer (nullable = true)\n",
            " |-- Fare: double (nullable = true)\n",
            " |-- Embarked: string (nullable = true)\n",
            " |-- Family_Size: integer (nullable = true)\n",
            " |-- Alone: integer (nullable = true)\n",
            "\n",
            "+--------+------+------+----+-----+-----+-------+--------+-----------+-----+\n",
            "|Survived|Pclass|   Sex| Age|SibSp|Parch|   Fare|Embarked|Family_Size|Alone|\n",
            "+--------+------+------+----+-----+-----+-------+--------+-----------+-----+\n",
            "|       0|     3|  male|22.0|    1|    0|   7.25|       S|          1|    0|\n",
            "|       1|     1|female|38.0|    1|    0|71.2833|       C|          1|    0|\n",
            "|       1|     3|female|26.0|    0|    0|  7.925|       S|          0|    1|\n",
            "|       1|     1|female|35.0|    1|    0|   53.1|       S|          1|    0|\n",
            "|       0|     3|  male|35.0|    0|    0|   8.05|       S|          0|    1|\n",
            "+--------+------+------+----+-----+-----+-------+--------+-----------+-----+\n",
            "only showing top 5 rows\n",
            "\n"
          ]
        }
      ],
      "source": [
        "# Read the dataset into a DataFrame\n",
        "titanic_df = spark.read.parquet(\"train.parquet\")\n",
        "\n",
        "# Load your dataset into a Spark DataFrame\n",
        "data = spark.read.csv(\"your_data.csv\", header=True, inferSchema=True)\n",
        "\n",
        "# Prepare features vector\n",
        "feature_columns = data.columns[:-1]\n",
        "assembler = VectorAssembler(inputCols=feature_columns, outputCol=\"features\")\n",
        "data = assembler.transform(data)\n",
        "\n",
        "\n",
        "train_data, test_data = data.randomSplit([0.8, 0.2], seed=123)\n",
        "\n",
        "\n",
        "# Specify the layers of the neural network\n",
        "layers = [len(feature_columns), 10, 5, 2]  # Example architecture: input layer, two hidden layers, output layer\n",
        "\n",
        "# Define the neural network classifier\n",
        "nn_classifier = MultilayerPerceptronClassifier(layers=layers, seed=123)\n",
        "\n",
        "# Train the model\n",
        "model = nn_classifier.fit(train_data)\n",
        "\n",
        "\n",
        "# Make predictions on test data\n",
        "predictions = model.transform(test_data)\n",
        "\n",
        "# Evaluate the model\n",
        "evaluator = MulticlassClassificationEvaluator(metricName=\"accuracy\")\n",
        "accuracy = evaluator.evaluate(predictions)\n",
        "print(\"Test Accuracy:\", accuracy)\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kXPFJ9DCWppu",
        "outputId": "c96df26d-b32e-49ba-c899-bc1bff71bda3"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "+--------+------+------+----+-----+-----+-------+--------+-----------+-----+\n",
            "|Survived|Pclass|   Sex| Age|SibSp|Parch|   Fare|Embarked|Family_Size|Alone|\n",
            "+--------+------+------+----+-----+-----+-------+--------+-----------+-----+\n",
            "|       0|     3|  male|22.0|    1|    0|   7.25|       S|          1|    0|\n",
            "|       1|     1|female|38.0|    1|    0|71.2833|       C|          1|    0|\n",
            "|       1|     3|female|26.0|    0|    0|  7.925|       S|          0|    1|\n",
            "|       1|     1|female|35.0|    1|    0|   53.1|       S|          1|    0|\n",
            "|       0|     3|  male|35.0|    0|    0|   8.05|       S|          0|    1|\n",
            "|       0|     3|  male|30.0|    0|    0| 8.4583|       Q|          0|    1|\n",
            "|       0|     1|  male|54.0|    0|    0|51.8625|       S|          0|    1|\n",
            "|       0|     3|  male| 2.0|    3|    1| 21.075|       S|          4|    0|\n",
            "|       1|     3|female|27.0|    0|    2|11.1333|       S|          2|    0|\n",
            "|       1|     2|female|14.0|    1|    0|30.0708|       C|          1|    0|\n",
            "|       1|     3|female| 4.0|    1|    1|   16.7|       S|          2|    0|\n",
            "|       1|     1|female|58.0|    0|    0|  26.55|       S|          0|    1|\n",
            "|       0|     3|  male|20.0|    0|    0|   8.05|       S|          0|    1|\n",
            "|       0|     3|  male|39.0|    1|    5| 31.275|       S|          6|    0|\n",
            "|       0|     3|female|14.0|    0|    0| 7.8542|       S|          0|    1|\n",
            "|       1|     2|female|55.0|    0|    0|   16.0|       S|          0|    1|\n",
            "|       0|     3|  male| 2.0|    4|    1| 29.125|       Q|          5|    0|\n",
            "|       1|     2|  male|30.0|    0|    0|   13.0|       S|          0|    1|\n",
            "|       0|     3|female|31.0|    1|    0|   18.0|       S|          1|    0|\n",
            "|       1|     3|female|30.0|    0|    0|  7.225|       C|          0|    1|\n",
            "+--------+------+------+----+-----+-----+-------+--------+-----------+-----+\n",
            "only showing top 20 rows\n",
            "\n"
          ]
        }
      ],
      "source": [
        "\n",
        "#Выведите значения датафрейма с помощью метода show()\n",
        "titanic_df.show()\n",
        "\n",
        "# Мы будем классифицировать, погибнет или выживет пассажир Титаника\n",
        "# Целевой признак - Survived\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DsnviqkqWppu"
      },
      "outputs": [],
      "source": [
        "# Поработаем с категориальными признаками.\n",
        "\n",
        "#Функция StringIndexer индексирует (энкодит) строки\n",
        "#Концепция, лежащая в основе индексирования строк, очень интуитивно понятна.\n",
        "#Мы просто заменяем каждую категорию номером.\n",
        "\n",
        "sex_index = StringIndexer(inputCol='Sex', outputCol=\"Sex_index\")  #StringIndexer - это Estimator, который нам формирует Transformer для преобразования данных\n",
        "embarked_index = StringIndexer(inputCol='Embarked', outputCol=\"Embarked_index\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7AEBrRe-Wppv"
      },
      "outputs": [],
      "source": [
        "# теперь применим новые столбцы к нашему датафрейму. Сначала обращаемся ним и выполняем операцию fit на нашем датафрейме.\n",
        "#После чего мы получим функцию трансформер и сможем вызвать ф-ию transform для того, чтобы выполнить преобразование наших данных\n",
        "\n",
        "titanic_df = sex_index.fit(titanic_df).transform(titanic_df)\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BTy3mLzRWppw"
      },
      "outputs": [],
      "source": [
        "titanic_df = embarked_index.fit(titanic_df).transform(titanic_df)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NpPWgq2RWppw"
      },
      "outputs": [],
      "source": [
        "# Сделайте преобразование для embarked_index\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8i4vhT28Wppx",
        "outputId": "38539dc8-5476-4a71-8cc7-cfb5409c74de"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "+--------+------+------+----+-----+-----+-------+--------+-----------+-----+---------+--------------+\n",
            "|Survived|Pclass|   Sex| Age|SibSp|Parch|   Fare|Embarked|Family_Size|Alone|Sex_index|Embarked_index|\n",
            "+--------+------+------+----+-----+-----+-------+--------+-----------+-----+---------+--------------+\n",
            "|       0|     3|  male|22.0|    1|    0|   7.25|       S|          1|    0|      0.0|           0.0|\n",
            "|       1|     1|female|38.0|    1|    0|71.2833|       C|          1|    0|      1.0|           1.0|\n",
            "|       1|     3|female|26.0|    0|    0|  7.925|       S|          0|    1|      1.0|           0.0|\n",
            "|       1|     1|female|35.0|    1|    0|   53.1|       S|          1|    0|      1.0|           0.0|\n",
            "|       0|     3|  male|35.0|    0|    0|   8.05|       S|          0|    1|      0.0|           0.0|\n",
            "|       0|     3|  male|30.0|    0|    0| 8.4583|       Q|          0|    1|      0.0|           2.0|\n",
            "|       0|     1|  male|54.0|    0|    0|51.8625|       S|          0|    1|      0.0|           0.0|\n",
            "|       0|     3|  male| 2.0|    3|    1| 21.075|       S|          4|    0|      0.0|           0.0|\n",
            "|       1|     3|female|27.0|    0|    2|11.1333|       S|          2|    0|      1.0|           0.0|\n",
            "|       1|     2|female|14.0|    1|    0|30.0708|       C|          1|    0|      1.0|           1.0|\n",
            "|       1|     3|female| 4.0|    1|    1|   16.7|       S|          2|    0|      1.0|           0.0|\n",
            "|       1|     1|female|58.0|    0|    0|  26.55|       S|          0|    1|      1.0|           0.0|\n",
            "|       0|     3|  male|20.0|    0|    0|   8.05|       S|          0|    1|      0.0|           0.0|\n",
            "|       0|     3|  male|39.0|    1|    5| 31.275|       S|          6|    0|      0.0|           0.0|\n",
            "|       0|     3|female|14.0|    0|    0| 7.8542|       S|          0|    1|      1.0|           0.0|\n",
            "|       1|     2|female|55.0|    0|    0|   16.0|       S|          0|    1|      1.0|           0.0|\n",
            "|       0|     3|  male| 2.0|    4|    1| 29.125|       Q|          5|    0|      0.0|           2.0|\n",
            "|       1|     2|  male|30.0|    0|    0|   13.0|       S|          0|    1|      0.0|           0.0|\n",
            "|       0|     3|female|31.0|    1|    0|   18.0|       S|          1|    0|      1.0|           0.0|\n",
            "|       1|     3|female|30.0|    0|    0|  7.225|       C|          0|    1|      1.0|           1.0|\n",
            "+--------+------+------+----+-----+-----+-------+--------+-----------+-----+---------+--------------+\n",
            "only showing top 20 rows\n",
            "\n"
          ]
        }
      ],
      "source": [
        "titanic_df.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Fd40FCWpWppx"
      },
      "outputs": [],
      "source": [
        "# Наш dataframe готов к тому, чтобы применить к нему модель. Но мы хотим сначала выполнить векторизацию, чтобы данные можно было применять в моделе.\n",
        "# Формируем список признаков, которые мы будем использовать, как фичи.\n",
        "features = ['Pclass', 'Age', 'SibSp', 'SibSp', 'Parch', 'Fare', 'Alone', 'Sex_index', 'Embarked_index']"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "eUN58Y7VWppy"
      },
      "outputs": [],
      "source": [
        "feature = VectorAssembler(inputCols=features, outputCol=\"features\")\n",
        "#VectorAssembler объединяет заданный список столбцов в один векторный столбец.\n",
        "# Является, пожалуй, самым важным векторным преобразователем в PySpark,\n",
        "# поскольку модели машинного обучения требуют на вход векторы.\n",
        "\n",
        "# VectorAssembler - трансформер, соответственно, вызываем метод transform  и применяем его к нашему датафрейму.\n",
        "feature_vector= feature.transform(titanic_df)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NrffFCilWppy",
        "outputId": "a6877f73-bec6-4bd3-c0ba-89ed2cc444a1"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "+--------+------+------+----+-----+-----+-------+--------+-----------+-----+---------+--------------+--------------------+\n",
            "|Survived|Pclass|   Sex| Age|SibSp|Parch|   Fare|Embarked|Family_Size|Alone|Sex_index|Embarked_index|            features|\n",
            "+--------+------+------+----+-----+-----+-------+--------+-----------+-----+---------+--------------+--------------------+\n",
            "|       0|     3|  male|22.0|    1|    0|   7.25|       S|          1|    0|      0.0|           0.0|[3.0,22.0,1.0,1.0...|\n",
            "|       1|     1|female|38.0|    1|    0|71.2833|       C|          1|    0|      1.0|           1.0|[1.0,38.0,1.0,1.0...|\n",
            "|       1|     3|female|26.0|    0|    0|  7.925|       S|          0|    1|      1.0|           0.0|[3.0,26.0,0.0,0.0...|\n",
            "|       1|     1|female|35.0|    1|    0|   53.1|       S|          1|    0|      1.0|           0.0|[1.0,35.0,1.0,1.0...|\n",
            "|       0|     3|  male|35.0|    0|    0|   8.05|       S|          0|    1|      0.0|           0.0|(9,[0,1,5,6],[3.0...|\n",
            "+--------+------+------+----+-----+-----+-------+--------+-----------+-----+---------+--------------+--------------------+\n",
            "only showing top 5 rows\n",
            "\n"
          ]
        }
      ],
      "source": [
        "feature_vector.show(5)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xCbGOldIWppz"
      },
      "outputs": [],
      "source": [
        "(training_data, test_data) = feature_vector.randomSplit([0.8, 0.2],seed = 42)\n",
        "#Формируем тренировочный и тестовый датасет. 80% данных в тренировочный, остальные - в тестовый. Seed - параметр случайности"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Cw0SY5yoWppz",
        "outputId": "fc4e29a3-1f89-4c2e-c150-770ce3e95326"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "+--------+------+------+----+-----+-----+------+--------+-----------+-----+---------+--------------+--------------------+\n",
            "|Survived|Pclass|   Sex| Age|SibSp|Parch|  Fare|Embarked|Family_Size|Alone|Sex_index|Embarked_index|            features|\n",
            "+--------+------+------+----+-----+-----+------+--------+-----------+-----+---------+--------------+--------------------+\n",
            "|       0|     1|female| 2.0|    1|    2|151.55|       S|          3|    0|      1.0|           0.0|[1.0,2.0,1.0,1.0,...|\n",
            "|       0|     1|female|25.0|    1|    2|151.55|       S|          3|    0|      1.0|           0.0|[1.0,25.0,1.0,1.0...|\n",
            "|       0|     1|  male|18.0|    1|    0| 108.9|       C|          1|    0|      0.0|           1.0|[1.0,18.0,1.0,1.0...|\n",
            "|       0|     1|  male|19.0|    1|    0|  53.1|       S|          1|    0|      0.0|           0.0|[1.0,19.0,1.0,1.0...|\n",
            "|       0|     1|  male|19.0|    3|    2| 263.0|       S|          5|    0|      0.0|           0.0|[1.0,19.0,3.0,3.0...|\n",
            "+--------+------+------+----+-----+-----+------+--------+-----------+-----+---------+--------------+--------------------+\n",
            "only showing top 5 rows\n",
            "\n"
          ]
        }
      ],
      "source": [
        "training_data.show(5)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ADZ2UFiGWpp0"
      },
      "source": [
        "# ML models"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gaK7oR_wWpp0",
        "tags": []
      },
      "source": [
        "# LogisticRegression"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bQhjNNJrWpp0"
      },
      "outputs": [],
      "source": [
        "evaluator = MulticlassClassificationEvaluator(labelCol=\"Survived\", predictionCol=\"prediction\", metricName=\"accuracy\")\n",
        "\n",
        "#Сначала создаем объект evaluator. Указываем целевую колонку обучения модели - labelCol. далее указываем\n",
        "# имя колонки, где будет лежать предсказанное значение  - predictionCol. И указываем метрику для оценки качества модели."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IxqKG_RYWpp1",
        "outputId": "cbc2689b-81da-4ae2-ca62-171f9400bbc8"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "+----------+--------+--------------------+\n",
            "|prediction|Survived|            features|\n",
            "+----------+--------+--------------------+\n",
            "|       1.0|       0|[1.0,50.0,0.0,0.0...|\n",
            "|       1.0|       0|(9,[0,1,4,5],[1.0...|\n",
            "|       1.0|       0|[1.0,24.0,0.0,0.0...|\n",
            "|       0.0|       0|(9,[0,1,5,6],[1.0...|\n",
            "|       0.0|       0|(9,[0,1,5,6],[1.0...|\n",
            "+----------+--------+--------------------+\n",
            "only showing top 5 rows\n",
            "\n"
          ]
        }
      ],
      "source": [
        "from pyspark.ml.classification import LogisticRegression\n",
        "lr = LogisticRegression(labelCol=\"Survived\", featuresCol=\"features\") # labelCol=\"Survived\" - целевая фича,  featuresCol=\"features\" - фичи, которые\n",
        "#используются для предсказания занчения целевой колонки\n",
        "\n",
        "lrModel = lr.fit(training_data) # получаем обученную модель.\n",
        "\n",
        "lr_prediction = lrModel.transform(test_data) # применяем модель на данных, получаем предсказание\n",
        "lr_prediction.select(\"prediction\", \"Survived\", \"features\").show(5)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "O_cPn1a3Wpp2",
        "outputId": "95e2730c-8e17-4beb-d438-22588eb053a0"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "LogisticRegression [Accuracy] = 0.813793\n",
            "LogisticRegression [Error] = 0.186207 \n"
          ]
        }
      ],
      "source": [
        "# Применяем оценщик (evaluator), чтобы узнать точность модели.\n",
        "lr_accuracy = evaluator.evaluate(lr_prediction)\n",
        "print(\"LogisticRegression [Accuracy] = %g\"% (lr_accuracy))\n",
        "print(\"LogisticRegression [Error] = %g \" % (1.0 - lr_accuracy))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-WVOeNlrWpp3",
        "tags": []
      },
      "source": [
        "# DecisionTreeClassifier"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "c_4Z1jFuWpp3",
        "outputId": "02cdf6e2-8367-42b8-e5c5-8930d16b8528"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "+----------+--------+--------------------+\n",
            "|prediction|Survived|            features|\n",
            "+----------+--------+--------------------+\n",
            "|       1.0|       0|[1.0,50.0,0.0,0.0...|\n",
            "|       0.0|       0|(9,[0,1,4,5],[1.0...|\n",
            "|       0.0|       0|[1.0,24.0,0.0,0.0...|\n",
            "|       0.0|       0|(9,[0,1,5,6],[1.0...|\n",
            "|       0.0|       0|(9,[0,1,5,6],[1.0...|\n",
            "+----------+--------+--------------------+\n",
            "only showing top 5 rows\n",
            "\n"
          ]
        }
      ],
      "source": [
        "from pyspark.ml.classification import DecisionTreeClassifier\n",
        "dt = DecisionTreeClassifier(labelCol=\"Survived\", featuresCol=\"features\")\n",
        "dt_model = dt.fit(training_data)\n",
        "dt_prediction = dt_model.transform(test_data)\n",
        "\n",
        "dt_prediction.select(\"prediction\", \"Survived\", \"features\").show(5)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WCbA7mb8Wpp4",
        "outputId": "ffb3fc7b-4706-44bb-d65a-6ad771601e50"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "DecisionTreeClassifier [Accuracy] = 0.82069\n",
            "DecisionTreeClassifier [Error] = 0.17931 \n"
          ]
        }
      ],
      "source": [
        "dt_accuracy = evaluator.evaluate(dt_prediction)\n",
        "print(\"DecisionTreeClassifier [Accuracy] = %g\"% (dt_accuracy))\n",
        "print(\"DecisionTreeClassifier [Error] = %g \" % (1.0 - dt_accuracy))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ob05g2G-Wpp4",
        "tags": []
      },
      "source": [
        "# RandomForestClassifier"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fH2ME7YYWpp5"
      },
      "source": [
        "Реализуйте самостоятельно и оцените точность, как в примерах выше"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "e5mTDJG_Wpp5",
        "outputId": "47788a73-f1dd-42d5-bdfa-97dfcf353135"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "+----------+--------+--------------------+\n",
            "|prediction|Survived|            features|\n",
            "+----------+--------+--------------------+\n",
            "|       1.0|       0|[1.0,50.0,0.0,0.0...|\n",
            "|       1.0|       0|(9,[0,1,4,5],[1.0...|\n",
            "|       0.0|       0|[1.0,24.0,0.0,0.0...|\n",
            "|       0.0|       0|(9,[0,1,5,6],[1.0...|\n",
            "|       0.0|       0|(9,[0,1,5,6],[1.0...|\n",
            "+----------+--------+--------------------+\n",
            "only showing top 5 rows\n",
            "\n",
            "RandomForestClassifier [Accuracy] = 0.813793\n",
            "RandomForestClassifier [Error] = 0.186207\n"
          ]
        }
      ],
      "source": [
        "from pyspark.ml.classification import RandomForestClassifier\n",
        "\n",
        "# Define Random Forest classifier with labelCol and featuresCol specified\n",
        "rf = RandomForestClassifier(labelCol=\"Survived\", featuresCol=\"features\")\n",
        "\n",
        "# Train the Random Forest classifier on the training data\n",
        "rf_model = rf.fit(training_data)\n",
        "\n",
        "# Make predictions on the test data using the trained model\n",
        "rf_prediction = rf_model.transform(test_data)\n",
        "\n",
        "\n",
        "rf_prediction.select(\"prediction\", \"Survived\", \"features\").show(5)\n",
        "\n",
        "\n",
        "# Evaluate the Random Forest classifier model using the MulticlassClassificationEvaluator\n",
        "rf_accuracy = evaluator.evaluate(rf_prediction)\n",
        "\n",
        "# Print the accuracy and error of the Random Forest classifier\n",
        "print(\"RandomForestClassifier [Accuracy] = %g\" % rf_accuracy)\n",
        "print(\"RandomForestClassifier [Error] = %g\" % (1.0 - rf_accuracy))\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OLslRtOOWpp5",
        "tags": []
      },
      "source": [
        "# Gradient-boosted tree classifier"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AxCkpq1aWpp5"
      },
      "source": [
        "Реализуйте самостоятельно и оцените точность, как в примерах выше"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8sF8i7YwWpp6",
        "outputId": "46814c4f-3f7b-4ce3-bc00-3ee2bcd1b062"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "+----------+--------+--------------------+\n",
            "|prediction|Survived|            features|\n",
            "+----------+--------+--------------------+\n",
            "|       1.0|       0|[1.0,50.0,0.0,0.0...|\n",
            "|       0.0|       0|(9,[0,1,4,5],[1.0...|\n",
            "|       0.0|       0|[1.0,24.0,0.0,0.0...|\n",
            "|       1.0|       0|(9,[0,1,5,6],[1.0...|\n",
            "|       1.0|       0|(9,[0,1,5,6],[1.0...|\n",
            "+----------+--------+--------------------+\n",
            "only showing top 5 rows\n",
            "\n",
            "Gradient-Boosted Tree Classifier [Accuracy] = 0.862069\n",
            "Gradient-Boosted Tree Classifier [Error] = 0.137931\n"
          ]
        }
      ],
      "source": [
        "from pyspark.ml.classification import GBTClassifier\n",
        "\n",
        "# Define Gradient-Boosted Tree classifier with labelCol and featuresCol specified\n",
        "gbt = GBTClassifier(labelCol=\"Survived\", featuresCol=\"features\")\n",
        "\n",
        "# Train the Gradient-Boosted Tree classifier on the training data\n",
        "gbt_model = gbt.fit(training_data)\n",
        "\n",
        "# Make predictions on the test data using the trained model\n",
        "gbt_prediction = gbt_model.transform(test_data)\n",
        "\n",
        "gbt_prediction.select(\"prediction\", \"Survived\", \"features\").show(5)\n",
        "\n",
        "# Evaluate the Gradient-Boosted Tree classifier model using the MulticlassClassificationEvaluator\n",
        "gbt_accuracy = evaluator.evaluate(gbt_prediction)\n",
        "\n",
        "# Print the accuracy and error of the Gradient-Boosted Tree classifier\n",
        "print(\"Gradient-Boosted Tree Classifier [Accuracy] = %g\" % gbt_accuracy)\n",
        "print(\"Gradient-Boosted Tree Classifier [Error] = %g\" % (1.0 - gbt_accuracy))\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AC1j-bDYWpp6",
        "tags": []
      },
      "source": [
        "# Save & Load Model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bqWorkQWWpp6"
      },
      "outputs": [],
      "source": [
        "# обученную модель мы можем сохранять. Сохраним модель RandomForest.\n",
        "rf_model.write().overwrite().save('rf_model')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 155
        },
        "id": "nzgrGLIkWpp6",
        "outputId": "83d6f3e9-affb-4102-af64-ac41700372c0"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div style=\"max-width:800px; border: 1px solid var(--colab-border-color);\"><style>\n",
              "      pre.function-repr-contents {\n",
              "        overflow-x: auto;\n",
              "        padding: 8px 12px;\n",
              "        max-height: 500px;\n",
              "      }\n",
              "\n",
              "      pre.function-repr-contents.function-repr-contents-collapsed {\n",
              "        cursor: pointer;\n",
              "        max-height: 100px;\n",
              "      }\n",
              "    </style>\n",
              "    <pre style=\"white-space: initial; background:\n",
              "         var(--colab-secondary-surface-color); padding: 8px 12px;\n",
              "         border-bottom: 1px solid var(--colab-border-color);\"><b>pyspark.ml.classification.RandomForestClassificationModel</b><br/>def __init__(java_model: Optional[&#x27;JavaObject&#x27;]=None)</pre><pre class=\"function-repr-contents function-repr-contents-collapsed\" style=\"\"><a class=\"filepath\" style=\"display:none\" href=\"#\">/usr/local/lib/python3.10/dist-packages/pyspark/ml/classification.py</a>Model fitted by RandomForestClassifier.\n",
              "\n",
              ".. versionadded:: 1.4.0</pre>\n",
              "      <script>\n",
              "      if (google.colab.kernel.accessAllowed && google.colab.files && google.colab.files.view) {\n",
              "        for (const element of document.querySelectorAll('.filepath')) {\n",
              "          element.style.display = 'block'\n",
              "          element.onclick = (event) => {\n",
              "            event.preventDefault();\n",
              "            event.stopPropagation();\n",
              "            google.colab.files.view(element.textContent, 2250);\n",
              "          };\n",
              "        }\n",
              "      }\n",
              "      for (const element of document.querySelectorAll('.function-repr-contents')) {\n",
              "        element.onclick = (event) => {\n",
              "          event.preventDefault();\n",
              "          event.stopPropagation();\n",
              "          element.classList.toggle('function-repr-contents-collapsed');\n",
              "        };\n",
              "      }\n",
              "      </script>\n",
              "      </div>"
            ],
            "text/plain": [
              "pyspark.ml.classification.RandomForestClassificationModel"
            ]
          },
          "execution_count": 38,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Теперь модель загрузим. Для этого сначала модключим нужный класс\n",
        "from pyspark.ml.classification import RandomForestClassificationModel\n",
        "type(RandomForestClassificationModel.load('rf_model'))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZD7hwefpWpp7",
        "tags": []
      },
      "source": [
        "# Pipeline"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "99fbFd8MWpp7"
      },
      "outputs": [],
      "source": [
        "from pyspark.ml.pipeline import PipelineModel\n",
        "\n",
        "# pipeline упрощает процесс внедрения ваших моделей в нужное окружение.\n",
        "\n",
        "# Перед тем, как модель обучить, мы уже выполнили какие-то преобразования данных.\n",
        "# Когда мы модель внедряем, нам нужно внедрять и все преобразования над данными.\n",
        "# Соответственно, появляется место для ошибок (человеческий фактор). Какую-то предобработку могут забыть сделать или сделать неправильно.\n",
        "# Пайплайны позволяют собрать вашу модель вместе с трансформациями."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bdfnQzizWpp8"
      },
      "outputs": [],
      "source": [
        "titanic_df = spark.read.parquet('train.parquet')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ms7u4fAQWpp8",
        "outputId": "7c8200b4-0308-4b23-b0a6-8d26aa27b1db"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "+--------+------+------+----+-----+-----+-------+--------+-----------+-----+\n",
            "|Survived|Pclass|   Sex| Age|SibSp|Parch|   Fare|Embarked|Family_Size|Alone|\n",
            "+--------+------+------+----+-----+-----+-------+--------+-----------+-----+\n",
            "|       0|     3|  male|22.0|    1|    0|   7.25|       S|          1|    0|\n",
            "|       1|     1|female|38.0|    1|    0|71.2833|       C|          1|    0|\n",
            "|       1|     3|female|26.0|    0|    0|  7.925|       S|          0|    1|\n",
            "|       1|     1|female|35.0|    1|    0|   53.1|       S|          1|    0|\n",
            "|       0|     3|  male|35.0|    0|    0|   8.05|       S|          0|    1|\n",
            "|       0|     3|  male|30.0|    0|    0| 8.4583|       Q|          0|    1|\n",
            "|       0|     1|  male|54.0|    0|    0|51.8625|       S|          0|    1|\n",
            "|       0|     3|  male| 2.0|    3|    1| 21.075|       S|          4|    0|\n",
            "|       1|     3|female|27.0|    0|    2|11.1333|       S|          2|    0|\n",
            "|       1|     2|female|14.0|    1|    0|30.0708|       C|          1|    0|\n",
            "|       1|     3|female| 4.0|    1|    1|   16.7|       S|          2|    0|\n",
            "|       1|     1|female|58.0|    0|    0|  26.55|       S|          0|    1|\n",
            "|       0|     3|  male|20.0|    0|    0|   8.05|       S|          0|    1|\n",
            "|       0|     3|  male|39.0|    1|    5| 31.275|       S|          6|    0|\n",
            "|       0|     3|female|14.0|    0|    0| 7.8542|       S|          0|    1|\n",
            "|       1|     2|female|55.0|    0|    0|   16.0|       S|          0|    1|\n",
            "|       0|     3|  male| 2.0|    4|    1| 29.125|       Q|          5|    0|\n",
            "|       1|     2|  male|30.0|    0|    0|   13.0|       S|          0|    1|\n",
            "|       0|     3|female|31.0|    1|    0|   18.0|       S|          1|    0|\n",
            "|       1|     3|female|30.0|    0|    0|  7.225|       C|          0|    1|\n",
            "+--------+------+------+----+-----+-----+-------+--------+-----------+-----+\n",
            "only showing top 20 rows\n",
            "\n"
          ]
        }
      ],
      "source": [
        "titanic_df.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "000q1Vf6Wpp8"
      },
      "outputs": [],
      "source": [
        "train, test = titanic_df.randomSplit([0.8, 0.2])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7hIaynQbWpp9",
        "outputId": "ca7fa00c-4203-4397-ab7f-d82e2c096fe2"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "+--------+------+------+----+-----+-----+-------+--------+-----------+-----+\n",
            "|Survived|Pclass|   Sex| Age|SibSp|Parch|   Fare|Embarked|Family_Size|Alone|\n",
            "+--------+------+------+----+-----+-----+-------+--------+-----------+-----+\n",
            "|       0|     1|female| 2.0|    1|    2| 151.55|       S|          3|    0|\n",
            "|       0|     1|female|25.0|    1|    2| 151.55|       S|          3|    0|\n",
            "|       0|     1|female|50.0|    0|    0|28.7125|       C|          0|    1|\n",
            "|       0|     1|  male|18.0|    1|    0|  108.9|       C|          1|    0|\n",
            "|       0|     1|  male|19.0|    1|    0|   53.1|       S|          1|    0|\n",
            "+--------+------+------+----+-----+-----+-------+--------+-----------+-----+\n",
            "only showing top 5 rows\n",
            "\n"
          ]
        }
      ],
      "source": [
        "train.show(5)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LeaP_qpsWpqS"
      },
      "outputs": [],
      "source": [
        "indexer_sex = StringIndexer(inputCol=\"Sex\", outputCol=\"Sex_index\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "D8OEtn3FWpqS"
      },
      "outputs": [],
      "source": [
        "indexer_embarked = StringIndexer(inputCol=\"Embarked\", outputCol=\"Embarked_index\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "a4ujGKheWpqT"
      },
      "outputs": [],
      "source": [
        "feature = VectorAssembler(\n",
        "    inputCols=[\"Pclass\",\"Age\",\"SibSp\",\"Parch\",\"Fare\",\"Family_Size\",\"Embarked_index\",\"Sex_index\"],\n",
        "    outputCol=\"features\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0BHKS7E9WpqT"
      },
      "outputs": [],
      "source": [
        "rf_classifier = RandomForestClassifier(labelCol=\"Survived\", featuresCol=\"features\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "UCb0OoOKWpqU"
      },
      "outputs": [],
      "source": [
        "pipeline = Pipeline(stages=[indexer_sex, indexer_embarked, feature, rf_classifier])\n",
        "# Определились с моделью созддаём Pipeline. Указываем массив из трансформаций, которые необходимо выполнить.\n",
        "# Собранный Pipeline является Estimator'ом, вызываем метод fit, из датафрейма (начального) в одно действие получается готовая модель."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "EnyRWQJHWpqU"
      },
      "outputs": [],
      "source": [
        "p_model = pipeline.fit(train)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 155
        },
        "id": "trAzeLfrWpqU",
        "outputId": "310af630-2e84-4f1e-8a1a-c6078d02f5e9"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div style=\"max-width:800px; border: 1px solid var(--colab-border-color);\"><style>\n",
              "      pre.function-repr-contents {\n",
              "        overflow-x: auto;\n",
              "        padding: 8px 12px;\n",
              "        max-height: 500px;\n",
              "      }\n",
              "\n",
              "      pre.function-repr-contents.function-repr-contents-collapsed {\n",
              "        cursor: pointer;\n",
              "        max-height: 100px;\n",
              "      }\n",
              "    </style>\n",
              "    <pre style=\"white-space: initial; background:\n",
              "         var(--colab-secondary-surface-color); padding: 8px 12px;\n",
              "         border-bottom: 1px solid var(--colab-border-color);\"><b>pyspark.ml.pipeline.PipelineModel</b><br/>def __init__(stages: List[Transformer])</pre><pre class=\"function-repr-contents function-repr-contents-collapsed\" style=\"\"><a class=\"filepath\" style=\"display:none\" href=\"#\">/usr/local/lib/python3.10/dist-packages/pyspark/ml/pipeline.py</a>Represents a compiled pipeline with transformers and fitted models.\n",
              "\n",
              ".. versionadded:: 1.3.0</pre>\n",
              "      <script>\n",
              "      if (google.colab.kernel.accessAllowed && google.colab.files && google.colab.files.view) {\n",
              "        for (const element of document.querySelectorAll('.filepath')) {\n",
              "          element.style.display = 'block'\n",
              "          element.onclick = (event) => {\n",
              "            event.preventDefault();\n",
              "            event.stopPropagation();\n",
              "            google.colab.files.view(element.textContent, 290);\n",
              "          };\n",
              "        }\n",
              "      }\n",
              "      for (const element of document.querySelectorAll('.function-repr-contents')) {\n",
              "        element.onclick = (event) => {\n",
              "          event.preventDefault();\n",
              "          event.stopPropagation();\n",
              "          element.classList.toggle('function-repr-contents-collapsed');\n",
              "        };\n",
              "      }\n",
              "      </script>\n",
              "      </div>"
            ],
            "text/plain": [
              "pyspark.ml.pipeline.PipelineModel"
            ]
          },
          "execution_count": 50,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "type(p_model)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XQ3DQOD-WpqV"
      },
      "outputs": [],
      "source": [
        "p_model.write().overwrite().save('p_model')\n",
        "# сохраним модель с перезаписью."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2ItP6vjsWpqV"
      },
      "outputs": [],
      "source": [
        "model = PipelineModel.load('p_model')\n",
        "# Загрузим модель."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "K3eMaROCWpqW"
      },
      "outputs": [],
      "source": [
        "prediction = p_model.transform(test)\n",
        "# применим модель, вызовем метод transrorm, применим его к выборке test"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "D7WVK69WWpqW",
        "outputId": "9a95188e-c379-4f91-d3f9-5cf03cc229c6"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "+--------+------+----+----+-----+-----+-------+--------+-----------+-----+\n",
            "|Survived|Pclass| Sex| Age|SibSp|Parch|   Fare|Embarked|Family_Size|Alone|\n",
            "+--------+------+----+----+-----+-----+-------+--------+-----------+-----+\n",
            "|       0|     1|male|30.0|    0|    0| 25.925|       S|          0|    1|\n",
            "|       0|     1|male|30.0|    0|    0|27.7208|       C|          0|    1|\n",
            "|       0|     1|male|30.0|    0|    0|30.6958|       C|          0|    1|\n",
            "|       0|     1|male|30.0|    0|    0|   31.0|       S|          0|    1|\n",
            "|       0|     1|male|30.0|    0|    0|   39.6|       C|          0|    1|\n",
            "+--------+------+----+----+-----+-----+-------+--------+-----------+-----+\n",
            "only showing top 5 rows\n",
            "\n"
          ]
        }
      ],
      "source": [
        "test.show(5)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "G3tWZ0CQWpqW",
        "outputId": "c8054fec-b227-4d64-d592-151817bc776f"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "+------+----+-----+-----+-------+-----------+--------------+---------+----------+\n",
            "|Pclass| Age|SibSp|Parch|   Fare|Family_Size|Embarked_index|Sex_index|prediction|\n",
            "+------+----+-----+-----+-------+-----------+--------------+---------+----------+\n",
            "|     1|30.0|    0|    0| 25.925|          0|           0.0|      0.0|       0.0|\n",
            "|     1|30.0|    0|    0|27.7208|          0|           1.0|      0.0|       0.0|\n",
            "|     1|30.0|    0|    0|30.6958|          0|           1.0|      0.0|       0.0|\n",
            "|     1|30.0|    0|    0|   31.0|          0|           0.0|      0.0|       0.0|\n",
            "|     1|30.0|    0|    0|   39.6|          0|           1.0|      0.0|       0.0|\n",
            "+------+----+-----+-----+-------+-----------+--------------+---------+----------+\n",
            "only showing top 5 rows\n",
            "\n"
          ]
        }
      ],
      "source": [
        "prediction.select([\"Pclass\",\"Age\",\"SibSp\",\"Parch\",\"Fare\",\"Family_Size\",\"Embarked_index\",\"Sex_index\",\"prediction\"]).show(5)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "k-ffaIDzWpqX"
      },
      "outputs": [],
      "source": [
        "evaluator = MulticlassClassificationEvaluator(labelCol=\"Survived\", predictionCol=\"prediction\", metricName=\"accuracy\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5YWNf0f7WpqX",
        "outputId": "dc459345-98f7-4710-d7d4-bd2f48e4902d"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Pipeline model [Accuracy] = 0.772727\n",
            "Pipeline model [Error] = 0.227273 \n"
          ]
        }
      ],
      "source": [
        "p_accuracy = evaluator.evaluate(prediction)\n",
        "print(\"Pipeline model [Accuracy] = %g\"% (p_accuracy))\n",
        "print(\"Pipeline model [Error] = %g \" % (1.0 - p_accuracy))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QpjUJ0FLWpqY"
      },
      "source": [
        "Сделайте самостоятельно Pipeline для Градиентного Бустинга, проверьте точность на тестовой выборке."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Q13ooO_KoGTM",
        "outputId": "a16cc230-9e3a-41d1-8c50-1457b55ee353"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "+--------+------+------+----+-----+-----+-------+--------+-----------+-----+\n",
            "|Survived|Pclass|   Sex| Age|SibSp|Parch|   Fare|Embarked|Family_Size|Alone|\n",
            "+--------+------+------+----+-----+-----+-------+--------+-----------+-----+\n",
            "|       0|     3|  male|22.0|    1|    0|   7.25|       S|          1|    0|\n",
            "|       1|     1|female|38.0|    1|    0|71.2833|       C|          1|    0|\n",
            "|       1|     3|female|26.0|    0|    0|  7.925|       S|          0|    1|\n",
            "|       1|     1|female|35.0|    1|    0|   53.1|       S|          1|    0|\n",
            "|       0|     3|  male|35.0|    0|    0|   8.05|       S|          0|    1|\n",
            "|       0|     3|  male|30.0|    0|    0| 8.4583|       Q|          0|    1|\n",
            "|       0|     1|  male|54.0|    0|    0|51.8625|       S|          0|    1|\n",
            "|       0|     3|  male| 2.0|    3|    1| 21.075|       S|          4|    0|\n",
            "|       1|     3|female|27.0|    0|    2|11.1333|       S|          2|    0|\n",
            "|       1|     2|female|14.0|    1|    0|30.0708|       C|          1|    0|\n",
            "|       1|     3|female| 4.0|    1|    1|   16.7|       S|          2|    0|\n",
            "|       1|     1|female|58.0|    0|    0|  26.55|       S|          0|    1|\n",
            "|       0|     3|  male|20.0|    0|    0|   8.05|       S|          0|    1|\n",
            "|       0|     3|  male|39.0|    1|    5| 31.275|       S|          6|    0|\n",
            "|       0|     3|female|14.0|    0|    0| 7.8542|       S|          0|    1|\n",
            "|       1|     2|female|55.0|    0|    0|   16.0|       S|          0|    1|\n",
            "|       0|     3|  male| 2.0|    4|    1| 29.125|       Q|          5|    0|\n",
            "|       1|     2|  male|30.0|    0|    0|   13.0|       S|          0|    1|\n",
            "|       0|     3|female|31.0|    1|    0|   18.0|       S|          1|    0|\n",
            "|       1|     3|female|30.0|    0|    0|  7.225|       C|          0|    1|\n",
            "+--------+------+------+----+-----+-----+-------+--------+-----------+-----+\n",
            "only showing top 20 rows\n",
            "\n"
          ]
        }
      ],
      "source": [
        "titanic_df = spark.read.parquet('train.parquet')\n",
        "titanic_df.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yebiUZxSokb_",
        "outputId": "223b7c46-ba62-44d9-b4c0-b441550eafda"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "+--------+------+------+----+-----+-----+-------+--------+-----------+-----+\n",
            "|Survived|Pclass|   Sex| Age|SibSp|Parch|   Fare|Embarked|Family_Size|Alone|\n",
            "+--------+------+------+----+-----+-----+-------+--------+-----------+-----+\n",
            "|       0|     1|female| 2.0|    1|    2| 151.55|       S|          3|    0|\n",
            "|       0|     1|female|25.0|    1|    2| 151.55|       S|          3|    0|\n",
            "|       0|     1|female|50.0|    0|    0|28.7125|       C|          0|    1|\n",
            "|       0|     1|  male|18.0|    1|    0|  108.9|       C|          1|    0|\n",
            "|       0|     1|  male|19.0|    1|    0|   53.1|       S|          1|    0|\n",
            "+--------+------+------+----+-----+-----+-------+--------+-----------+-----+\n",
            "only showing top 5 rows\n",
            "\n"
          ]
        }
      ],
      "source": [
        "train_data, test_data = titanic_df.randomSplit([0.8, 0.2])\n",
        "train_data.show(5)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tbUEons7okKS"
      },
      "outputs": [],
      "source": [
        "indexed_sex = StringIndexer(inputCol=\"Sex\", outputCol=\"Sex_index\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "IxZoRWJMojYG"
      },
      "outputs": [],
      "source": [
        "indexed_embarked = StringIndexer(inputCol=\"Embarked\", outputCol=\"Embarked_index\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KEU7g-S7pNx3"
      },
      "outputs": [],
      "source": [
        "feature = VectorAssembler(\n",
        "    inputCols=[\"Pclass\",\"Age\",\"SibSp\",\"Parch\",\"Fare\",\"Family_Size\",\"Embarked_index\",\"Sex_index\"],\n",
        "    outputCol=\"features\")\n",
        "\n",
        "gbt_classifier = GBTClassifier(labelCol=\"Survived\", featuresCol=\"features\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 155
        },
        "id": "qK1r-pnupWMA",
        "outputId": "19482711-fc26-4c59-c7f5-dd9217e670ca"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div style=\"max-width:800px; border: 1px solid var(--colab-border-color);\"><style>\n",
              "      pre.function-repr-contents {\n",
              "        overflow-x: auto;\n",
              "        padding: 8px 12px;\n",
              "        max-height: 500px;\n",
              "      }\n",
              "\n",
              "      pre.function-repr-contents.function-repr-contents-collapsed {\n",
              "        cursor: pointer;\n",
              "        max-height: 100px;\n",
              "      }\n",
              "    </style>\n",
              "    <pre style=\"white-space: initial; background:\n",
              "         var(--colab-secondary-surface-color); padding: 8px 12px;\n",
              "         border-bottom: 1px solid var(--colab-border-color);\"><b>pyspark.ml.pipeline.PipelineModel</b><br/>def __init__(stages: List[Transformer])</pre><pre class=\"function-repr-contents function-repr-contents-collapsed\" style=\"\"><a class=\"filepath\" style=\"display:none\" href=\"#\">/usr/local/lib/python3.10/dist-packages/pyspark/ml/pipeline.py</a>Represents a compiled pipeline with transformers and fitted models.\n",
              "\n",
              ".. versionadded:: 1.3.0</pre>\n",
              "      <script>\n",
              "      if (google.colab.kernel.accessAllowed && google.colab.files && google.colab.files.view) {\n",
              "        for (const element of document.querySelectorAll('.filepath')) {\n",
              "          element.style.display = 'block'\n",
              "          element.onclick = (event) => {\n",
              "            event.preventDefault();\n",
              "            event.stopPropagation();\n",
              "            google.colab.files.view(element.textContent, 290);\n",
              "          };\n",
              "        }\n",
              "      }\n",
              "      for (const element of document.querySelectorAll('.function-repr-contents')) {\n",
              "        element.onclick = (event) => {\n",
              "          event.preventDefault();\n",
              "          event.stopPropagation();\n",
              "          element.classList.toggle('function-repr-contents-collapsed');\n",
              "        };\n",
              "      }\n",
              "      </script>\n",
              "      </div>"
            ],
            "text/plain": [
              "pyspark.ml.pipeline.PipelineModel"
            ]
          },
          "execution_count": 71,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "pipeline = Pipeline(stages=[indexed_sex, indexed_embarked, feature, gbt_classifier])\n",
        "a_model = pipeline.fit(train)\n",
        "type(a_model)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KAPh5mhzpV6Q",
        "outputId": "5c7b4d07-9b63-45cf-8e65-fdc2ac181f48"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "+--------+------+----+----+-----+-----+--------+--------+-----------+-----+\n",
            "|Survived|Pclass| Sex| Age|SibSp|Parch|    Fare|Embarked|Family_Size|Alone|\n",
            "+--------+------+----+----+-----+-----+--------+--------+-----------+-----+\n",
            "|       0|     1|male|19.0|    3|    2|   263.0|       S|          5|    0|\n",
            "|       0|     1|male|24.0|    0|    1|247.5208|       C|          1|    0|\n",
            "|       0|     1|male|28.0|    1|    0| 82.1708|       C|          1|    0|\n",
            "|       0|     1|male|30.0|    0|    0|     0.0|       S|          0|    1|\n",
            "|       0|     1|male|30.0|    0|    0|     0.0|       S|          0|    1|\n",
            "+--------+------+----+----+-----+-----+--------+--------+-----------+-----+\n",
            "only showing top 5 rows\n",
            "\n"
          ]
        }
      ],
      "source": [
        "p_model.write().overwrite().save('a_model')\n",
        "model2 = PipelineModel.load('a_model')\n",
        "\n",
        "prediction2 = p_model.transform(test_data)\n",
        "test_data.show(5)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OGh5Z3L_qrsw",
        "outputId": "46601957-17e0-4056-ce2b-75452409114e"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "+------+----+-----+-----+--------+-----------+--------------+---------+----------+\n",
            "|Pclass| Age|SibSp|Parch|    Fare|Family_Size|Embarked_index|Sex_index|prediction|\n",
            "+------+----+-----+-----+--------+-----------+--------------+---------+----------+\n",
            "|     1|19.0|    3|    2|   263.0|          5|           0.0|      0.0|       0.0|\n",
            "|     1|24.0|    0|    1|247.5208|          1|           1.0|      0.0|       0.0|\n",
            "|     1|28.0|    1|    0| 82.1708|          1|           1.0|      0.0|       0.0|\n",
            "|     1|30.0|    0|    0|     0.0|          0|           0.0|      0.0|       0.0|\n",
            "|     1|30.0|    0|    0|     0.0|          0|           0.0|      0.0|       0.0|\n",
            "+------+----+-----+-----+--------+-----------+--------------+---------+----------+\n",
            "only showing top 5 rows\n",
            "\n"
          ]
        }
      ],
      "source": [
        "prediction2.select([\"Pclass\",\"Age\",\"SibSp\",\"Parch\",\"Fare\",\"Family_Size\",\"Embarked_index\",\"Sex_index\",\"prediction\"]).show(5)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OX2ezoRCrNSP",
        "outputId": "ef09a92f-d2f8-4206-e1fa-9638325367d8"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Pipeline model [Accuracy] = 0.865854\n",
            "Pipeline model [Error] = 0.134146 \n"
          ]
        }
      ],
      "source": [
        "evaluator = MulticlassClassificationEvaluator(labelCol=\"Survived\", predictionCol=\"prediction\", metricName=\"accuracy\")\n",
        "p_accuracy = evaluator.evaluate(prediction2)\n",
        "print(\"Pipeline model [Accuracy] = %g\"% (p_accuracy))\n",
        "print(\"Pipeline model [Error] = %g \" % (1.0 - p_accuracy))"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.8"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
